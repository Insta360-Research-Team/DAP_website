<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Depth Any Panoramas: A Foundation Model for Panoramic Depth Estimation</title>
        <link rel="icon" href="favicon.png">
        <link rel="stylesheet" href="fonts/avenir-next/stylesheet.css">
        <link rel="stylesheet" href="fonts/segoe-print/stylesheet.css">
        <link rel="stylesheet" href="css/carousel.css">
        <link rel="stylesheet" href="icons/style.css">
        <link rel="stylesheet" href="css/selection_panel.css">
        <link rel="stylesheet" href="css/main.css">
        <script src="js/carousel.js"></script>
        <script src="js/selection_panel.js"></script>
        <script src="js/generation.js"></script>
        <script src="js/application.js"></script>
        <script src="js/main.js"></script>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
        };
        </script>
    </head>
    <body>
        <div id="main">
            <div style="text-align: center; font-family: Arial, sans-serif;">
    <!-- 大标题 -->
    <div style="
        font-size: 60px;
        font-weight: bold;
        background: linear-gradient(90deg, #6c57ff, #a46bff);
        -webkit-background-clip: text;
        color: transparent;
        margin-bottom: 15px;
    ">
        Depth Any Panoramas
    </div>

    <!-- 副标题 -->
    <div style="
        font-size: 34px;
        background: linear-gradient(90deg, #4286f4, #ff946c);
        -webkit-background-clip: text;
        color: transparent;
        line-height: 1.3;
    ">
        A Foundation Model for Panoramic Depth Estimation
    </div>
</div>


            <div id="authors">
                <div><a class="link" href="https://linxin0.github.io">Xin Lin</a><sup>2</sup></div>
                <div><a class="link" href="https://insta360-research-team.github.io/DAP_website">Meixi Song</a><sup>1</sup></div>
                <div><a class="link" href="https://insta360-research-team.github.io/DAP_website">Dizhe Zhang</a><sup>1 </sup></div>
                <div><a class="link" href="https://insta360-research-team.github.io/DAP_website">Wenxuan Lu</a><sup>1 </sup></div>
                <div><a class="link" href="https://insta360-research-team.github.io/DAP_website">Haodong Li</a><sup>2</sup></div>
                <div><a class="link" href="https://insta360-research-team.github.io/DAP_website">Bo Du</a><sup>3</sup></div>
                <div><a class="link" href="https://insta360-research-team.github.io/DAP_website">Ming-Hsuan Yang</a><sup>4</sup></div>
                <div><a class="link" href="https://insta360-research-team.github.io/DAP_website">Truong Nguyen</a><sup>2</sup></div>
                <div><a class="link" href="https://scholar.google.com.hk/citations?user=SSI90d4AAAAJ&hl=en&oi=ao">Lu Qi</a><sup>1,3</sup></div>
            </div>
            <div id="institution">
                <div><sup>1</sup><a class="link" href="https://www.insta360.com/cn/">Insta360 Research</a></div>
                <div><sup>2</sup><a class="link" href="https://ucsd.edu/">University of California San Diego</a></div>
                <div><sup>3</sup><a class="link" href="https://admission.whu.edu.cn/">Wuhan University</a></div>
                <div><sup>4</sup><a class="link" href="https://www.ucmerced.edu/">University of California, Merced</a></div>
            </div>
            <div id="links">
                <div><a id="arxiv" href="#arxiv">Arxiv</a></div>
                <div><a id="code" href="https://github.com/Insta360-Research-Team/DDGS">Code</a></div>
            </div>
            <div id="teaser">
                <div style="width: 100%;"><img src="assets/depth_teaser2.pdf" alt="TRELLIS Teaser" style="width: 100%; height: auto;"></div>
            </div>
            <div id="abstract" class="x-gradient-block">
                In this work, we present a panoramic metric depth foundation model that generalizes across diverse scene distances. We explore a data-in-the-loop paradigm from the view of both data construction and framework design. We collect a large-scale dataset by combining public datasets, high-quality synthetic data from our UE5 simulator and text-to-image models, and real panoramic images from the web. To reduce domain gaps between indoor/outdoor and synthetic/real data, we introduce a three-stage pseudo-label curation pipeline to generate reliable ground truth for unlabeled images. For the model, we adopt DINOv3-Large as the backbone for its strong pre-trained generalization, and introduce a plug-and-play range mask head, sharpness-centric optimization, and geometry-centric optimization to improve robustness to varying distances and enforce geometric consistency across views. Experiments on multiple benchmarks (e.g., Stanford2D3D, Matterport3D, and Deep360) demonstrate strong performance and zero-shot generalization, with particularly robust and stable metric predictions in diverse real-world scenes. .
            </div>


            <div class="x-section-title">
                <div class="x-gradient-font">Methodology <span style="font-size: 40px; font-weight:600;"></span> </div>
            </div>
            
            <div style="display: flex; justify-content: center; margin: 20px 0;">
                <div class="x-card" style="width: 100%; max-width: 1200px; margin: 10px auto;">
                    <div style="width: 100%; text-align: center;">
                        <img src="assets/pipeline-2.pdf" alt="" style="width: 100%; height: auto; border-radius: 8px;">
                    </div>
                    <div style="width: 100%; text-align: center; font-size: 18px; margin-top: 10px; line-height: 1.45;">
                        <strong>Overview of the proposed progressive three-stage pipeline.</strong>
                        Stage 1 trains a <strong>Scene-Invariant Labeler</strong> on high-quality synthetic indoor and outdoor data 
                        to provide strong initialization. Stage 2 introduces a <strong>Realism-Invariant Labeler</strong>, 
                        where a PatchGAN-based discriminator selects 300K indoor and 300K outdoor high-confidence pseudo-labeled 
                        samples to mitigate domain gaps between synthetic and real data. Stage 3 performs <strong>DAP</strong> training 
                        on all labeled and pseudo-labeled data, enabling large-scale semi-supervised learning and strong generalization 
                        across real-world panoramic scenes.
                    </div>
                    <div style="width: 100%; text-align: center;">
                        <img src="assets/depth_framework.pdf" alt="" style="width: 100%; height: auto; border-radius: 8px;">
                    </div>

                    <div style="width: 100%; text-align: center; font-size: 18px; margin-top: 10px; line-height: 1.45;">
                        <strong>Architecture of the proposed DAP network.</strong> 
                        Built upon DINOv3-Large as the visual backbone, our model adopts a distortion-aware depth decoder 
                        and a plug-and-play range mask head for adaptive distance control across diverse scenes. 
                        Training is guided by multi-level geometric and sharpness-aware losses, including 
                        <strong>LSILog</strong>, <strong>LDF</strong>, <strong>Lgrad</strong>, <strong>Lnormal</strong>, and <strong>Lpts</strong>, ensuring metric accuracy, 
                        edge fidelity, and geometric consistency in panoramic depth estimation.
                    
                    </div>
                </div>
            </div>

            
            <div class="x-section-title">
                <div class="x-gradient-font">Qualitative Evaluation <span style="font-size: 40px; font-weight:600;"></span> </div>
            </div>
            
            <div style="display: flex; justify-content: center; margin: 20px 0;">
                <div class="x-card" style="width: 100%; max-width: 1200px; margin: 10px auto;">
                    <div style="width: 100%; text-align: center;">
                        <img src="assets/compare_real2.pdf" alt="" style="width: 100%; height: auto; border-radius: 8px;">
                    </div>
                    <div style="width: 100%; text-align: center;">
                        <img src="assets/compare_synthetic2.pdf" alt="" style="width: 100%; height: auto; border-radius: 8px;">
                    </div>
                </div>
            </div>
            
            


        
            <!-- Citation -->
          <section>
            <h2>Citation</h2>
        <pre>
        @article{lin2025dap,
          title={Depth Any Panoramas: A Foundation Model for Panoramic Depth Estimation},
          author={Lin, Xin and Song, Meixi and Zhang, Dizhe and Lu, Wenxuan and Li, Haodong and Du, Bo and Yang, Ming-Hsuan and Nguyen, Truong and Qi, Lu},
          journal={arXiv},
          year={2025}
        }
        </pre>
          </section>
            
            <div id="results-imr-selection"></div>


            <!-- <div class="x-section-title"><div class="x-gradient-font">Citation</div></div>
            <p>
                If you find our work useful, please consider citing:
            </p>
            <p class="bibtex x-gradient-block"> -->

        </div>
        <div id="bottombar">
            <div class="row">
                <div style="text-align: center; width: 100%;"><span style="font-size: 18px; font-weight: 500;">D<sup>2</sup>GS: Depth-and-Density Guided Gaussian Splatting for Stable and Accurate Sparse-View Reconstruction</span></div>
            </div>
        </div>
    </body>
</html>
